{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import isnan, when, count, col, lit, udf\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import re\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.extra.rate_limiter import RateLimiter\n",
    "from geopy import distance\n",
    "import pickle\n",
    "\n",
    "spark = SparkSession.builder.appName(\"tripDataCSVLoad\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Schema of data and read CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_schema_expression(path,samp_nrows=100):\n",
    "    int_types = [np.int64,int]\n",
    "    float_types = [np.float64,float]\n",
    "\n",
    "    df = pd.read_csv(path,nrows=samp_nrows)\n",
    "    cols_og = [i for i in df.columns.values]\n",
    "    cols_edited = [re.sub('[^a-zA-Z0-9_.]', '',i) for i in cols_og]\n",
    "\n",
    "    schema_list = []\n",
    "    col_list = []\n",
    "    for col in cols_og:\n",
    "        if df[col].dtype in int_types:\n",
    "            schema_str = str(col)+' int'\n",
    "        elif df[col].dtype in float_types:\n",
    "            schema_str = str(col)+' double'\n",
    "        else:\n",
    "            schema_str = str(col)+' string'\n",
    "        col_str = str(col) +' as '+re.sub('[^a-zA-Z0-9_.]', '',col)\n",
    "        schema_list.append(schema_str)\n",
    "        col_list.append(col_str)\n",
    "    schema_statement = ','.join(schema_list)\n",
    "    col_convert_dict = dict(list(zip(cols_og,cols_edited)))\n",
    "\n",
    "    return col_convert_dict,schema_statement\n",
    "\n",
    "tripdata_cols_dict,tripdata_schema = format_schema_expression(\"src/trip_data_4.csv\")\n",
    "tripfare_cols_dict,tripfare_schema = format_schema_expression(\"src/trip_fare_4.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tripdata=spark.read.csv(\"src/trip_data_4.csv\",\n",
    "                            header=True,\n",
    "                            inferSchema=True,\n",
    "                            quote='\"',\n",
    "                            schema=tripdata_schema)\n",
    "for key,val in tripdata_cols_dict.items():\n",
    "    df_tripdata = df_tripdata.withColumnRenamed(key,val)\n",
    "# print(df_tripdata.printSchema())\n",
    "\n",
    "df_tripfare=spark.read.csv(\"src/trip_fare_4.csv\",\n",
    "                            header=True,\n",
    "                            inferSchema=True,\n",
    "                            quote='\"',\n",
    "                            schema=tripfare_schema)\n",
    "for key,val in tripfare_cols_dict.items():\n",
    "    df_tripfare = df_tripfare.withColumnRenamed(key,val)\n",
    "# print(df_tripfare.printSchema())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['medallion', 'hack_license', 'vendor_id', 'rate_code', 'store_and_fwd_flag', 'pickup_datetime', 'dropoff_datetime', 'passenger_count', 'trip_time_in_secs', 'trip_distance', 'pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude']\n",
      "['medallion', 'hack_license', 'vendor_id', 'pickup_datetime', 'payment_type', 'fare_amount', 'surcharge', 'mta_tax', 'tip_amount', 'tolls_amount', 'total_amount']\n"
     ]
    }
   ],
   "source": [
    "# print(df_tripdata.schema.names)\n",
    "# print(df_tripfare.schema.names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Sanity Check and Cleasing\n",
    "#### A) tripdata\n",
    "##### 1) null values\n",
    "##### 2) pickup / dropoff datetime scope\n",
    "##### 3) passenger count\n",
    "##### 4) trip time\n",
    "##### 5) trip distance\n",
    "##### 6) pickup / dropoff latitude/longitude scope\n",
    "##### 7) pickup / dropoff latitude/longitude is identical\n",
    "#### B) tripfare\n",
    "##### 1) null values\n",
    "##### 2) fare amount\n",
    "##### 3) toll amount\n",
    "##### 4) surcharge\n",
    "##### 5) tip amount\n",
    "##### 6) mta_tax\n",
    "##### 7) total amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------+---------+---------+------------------+---------------+----------------+---------------+-----------------+-------------+----------------+---------------+-----------------+----------------+\n",
      "|medallion|hack_license|vendor_id|rate_code|store_and_fwd_flag|pickup_datetime|dropoff_datetime|passenger_count|trip_time_in_secs|trip_distance|pickup_longitude|pickup_latitude|dropoff_longitude|dropoff_latitude|\n",
      "+---------+------------+---------+---------+------------------+---------------+----------------+---------------+-----------------+-------------+----------------+---------------+-----------------+----------------+\n",
      "|        0|           0|        0|        0|           7518657|              0|               0|              0|                0|            0|               0|              0|              146|             146|\n",
      "+---------+------------+---------+---------+------------------+---------------+----------------+---------------+-----------------+-------------+----------------+---------------+-----------------+----------------+\n",
      "\n",
      "finished 1\n",
      "finished 2\n",
      "finished 3\n",
      "finished 4\n",
      "finished 5\n",
      "finished 6\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df_trip' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-09572961db3a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;31m## remove such records - 116577 rows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m \u001b[0mdf_trip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pickup_latitude'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dropoff_latitude'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m&\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pickup_longitude'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dropoff_longitude'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df_trip' is not defined"
     ]
    }
   ],
   "source": [
    "### Tripdata\n",
    "\n",
    "## 1) null values\n",
    "df_tripdata.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df_tripdata.columns]).show()\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------------\n",
    "#1. store_and_fwd_flag show highest null - 7518657. No need to remove as it has no meaningful implication\n",
    "#2. missing dropoff_longiture/ latitude - 146. To be removed\n",
    "#---------------------------------------------------------------------------------------------------------\n",
    "print('finished 1')\n",
    "# 2) pickup / dropoff datetime scope\n",
    "\n",
    "quantiles_pickup_datetime = df_tripdata.withColumn('pickup_datetime',F.to_timestamp('pickup_datetime'))\\\n",
    "    .select(F.percentile_approx(\"pickup_datetime\", [0.0,0.01,0.25, 0.5, 0.75,0.99,1.0], 1000000).alias(\"quantiles\")).collect()\n",
    "\n",
    "# pickup_datetime\n",
    "# [datetime.datetime(2013, 4, 1, 0, 0), datetime.datetime(2013, 4, 1, 12, 15, 42), \n",
    "# datetime.datetime(2013, 4, 8, 16, 38), datetime.datetime(2013, 4, 16, 1, 56), \n",
    "# datetime.datetime(2013, 4, 23, 14, 10, 32), datetime.datetime(2013, 4, 30, 18, 51), \n",
    "# datetime.datetime(2013, 4, 30, 23, 59, 58)]\n",
    "\n",
    "quantiles_dropoff_datetime = df_tripdata.withColumn('dropoff_datetime',F.to_timestamp('dropoff_datetime'))\\\n",
    "    .select(F.percentile_approx(\"dropoff_datetime\", [0.0,0.01,0.25, 0.5, 0.75,0.99,1.0], 1000000).alias(\"quantiles\")).collect()\n",
    "print('finished 2')\n",
    "# dropoff_datetime\n",
    "# [datetime.datetime(2013, 4, 1, 0, 0), datetime.datetime(2013, 4, 1, 12, 27, 2), \n",
    "# datetime.datetime(2013, 4, 8, 16, 51), datetime.datetime(2013, 4, 16, 2, 6), \n",
    "# datetime.datetime(2013, 4, 23, 14, 24), datetime.datetime(2013, 4, 30, 19, 3), \n",
    "# datetime.datetime(2013, 5, 1, 2, 19, 25)]\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------------\n",
    "#1. No suspicious pickup datetime\n",
    "#2. No suspicious dropoff datetime\n",
    "#---------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# 3) passenger count\n",
    "\n",
    "quantiles_passenger = df_tripdata\\\n",
    "    .select(F.percentile_approx(\"passenger_count\", [0.0,0.01,0.25, 0.5, 0.75,0.99,1.0], 1000000).alias(\"quantiles\")).collect()\n",
    "print('finished 3')\n",
    "# passenger count\n",
    "# [Row(quantiles=[0, 1, 1, 1, 2, 6, 9])]\n",
    "#---------------------------------------------------------------------------------------------------------\n",
    "#1. Remove passenger count == 0\n",
    "#---------------------------------------------------------------------------------------------------------\n",
    "\n",
    "##### 4) trip time\n",
    "\n",
    "quantiles_trip_time = df_tripdata\\\n",
    "    .select(F.percentile_approx(\"trip_time_in_secs\", [0.0,0.01,0.25, 0.5, 0.75,0.99,1.0], 1000000).alias(\"quantiles\")).collect()\n",
    "print('finished 4')\n",
    "# trip time\n",
    "# [Row(quantiles=[0, 60, 360, 600, 960, 2760, 10800])]\n",
    "#---------------------------------------------------------------------------------------------------------\n",
    "#1. Remove trip_time_in_secs == 0\n",
    "#---------------------------------------------------------------------------------------------------------\n",
    "\n",
    "##### 5) trip distance\n",
    "\n",
    "quantiles_trip_distance = df_tripdata\\\n",
    "    .select(F.percentile_approx(\"trip_distance\", [0.0,0.01,0.25, 0.5, 0.75,0.99,1.0], 1000000).alias(\"quantiles\")).collect()\n",
    "print('finished 5')\n",
    "# trip distance\n",
    "# [Row(quantiles=[0.0, 0.1, 1.04, 1.78, 3.2, 18.1, 100.0])]\n",
    "#---------------------------------------------------------------------------------------------------------\n",
    "#1. Remove trip_distance == 0\n",
    "#---------------------------------------------------------------------------------------------------------\n",
    "\n",
    "##### 6) pickup / dropoff latitude/longitude scope\n",
    "\n",
    "total_rows = df_tripdata.count()\n",
    "\n",
    "# df_tripdata.select('*',F.round(col('pickup_latitude')).alias('rounded_pickup_latitude'))\\\n",
    "#     .groupBy('rounded_pickup_latitude').count()\\\n",
    "#         .select(\"*\",(col(\"count\")/total_rows).alias('percentage'))\\\n",
    "#             .filter(\"`percentage` >= 0.01\").sort(F.desc('percentage')).show()\n",
    "\n",
    "# pickup_latitude - remove 0 latitude as it is invalid\n",
    "# +-----------------------+--------+--------------------+\n",
    "# |rounded_pickup_latitude|   count|          percentage|\n",
    "# +-----------------------+--------+--------------------+\n",
    "# |                   41.0|14848448|  0.9833104510403253|\n",
    "# |                    0.0|  250672|0.016600280203236086|\n",
    "# +-----------------------+--------+--------------------+\n",
    "\n",
    "valid_pickup_latitude = df_tripdata.select('*',F.round(col('pickup_latitude')).alias('rounded_pickup_latitude'))\\\n",
    "    .groupBy('rounded_pickup_latitude').count()\\\n",
    "        .select(\"*\",(col(\"count\")/total_rows).alias('percentage'))\\\n",
    "            .filter(\"`percentage` >= 0.01 and rounded_pickup_latitude <> 0\")\\\n",
    "            .sort(F.desc('percentage')).select('rounded_pickup_latitude').collect()\n",
    "\n",
    "valid_pickup_latitude_list = [int(row.rounded_pickup_latitude) for row in valid_pickup_latitude]\n",
    "\n",
    "# df_tripdata.select('*',F.round(col('dropoff_latitude')).alias('rounded_dropoff_latitude'))\\\n",
    "#     .groupBy('rounded_dropoff_latitude').count()\\\n",
    "#         .select(\"*\",(col(\"count\")/total_rows).alias('percentage'))\\\n",
    "#             .filter(\"`percentage` >= 0.01\").sort(F.desc('percentage')).show()\n",
    "\n",
    "# dropoff_latitude - remove 0 latitude as it is invalid\n",
    "# +------------------------+--------+--------------------+\n",
    "# |rounded_dropoff_latitude|   count|          percentage|\n",
    "# +------------------------+--------+--------------------+\n",
    "# |                    41.0|14839861|  0.9827417931682647|\n",
    "# |                     0.0|  259005|0.017152117404573158|\n",
    "# +------------------------+--------+--------------------+\n",
    "\n",
    "valid_dropoff_latitude = df_tripdata.select('*',F.round(col('dropoff_latitude')).alias('rounded_dropoff_latitude'))\\\n",
    "    .groupBy('rounded_dropoff_latitude').count()\\\n",
    "        .select(\"*\",(col(\"count\")/total_rows).alias('percentage'))\\\n",
    "            .filter(\"`percentage` >= 0.01 and rounded_dropoff_latitude <> 0\")\\\n",
    "            .sort(F.desc('percentage')).select('rounded_dropoff_latitude').collect()\n",
    "\n",
    "valid_dropoff_latitude_list = [int(row.rounded_dropoff_latitude) for row in valid_dropoff_latitude]\n",
    "\n",
    "# df_tripdata.select('*',F.round(col('pickup_longitude')).alias('rounded_pickup_longitude'))\\\n",
    "#     .groupBy('rounded_pickup_longitude').count()\\\n",
    "#         .select(\"*\",(col(\"count\")/total_rows).alias('percentage'))\\\n",
    "#             .filter(\"`percentage` >= 0.01\").sort(F.desc('percentage')).show()\n",
    "\n",
    "# pickup_longitude - remove 0 latitude as it is invalid\n",
    "# +------------------------+--------+--------------------+\n",
    "# |rounded_pickup_longitude|   count|          percentage|\n",
    "# +------------------------+--------+--------------------+\n",
    "# |                   -74.0|14845693|  0.9831280063637763|\n",
    "# |                     0.0|  253233|0.016769877595846697|\n",
    "# +------------------------+--------+--------------------+\n",
    "\n",
    "valid_pickup_longitude = df_tripdata.select('*',F.round(col('pickup_longitude')).alias('rounded_pickup_longitude'))\\\n",
    "    .groupBy('rounded_pickup_longitude').count()\\\n",
    "        .select(\"*\",(col(\"count\")/total_rows).alias('percentage'))\\\n",
    "            .filter(\"`percentage` >= 0.01 and rounded_pickup_longitude <> 0\")\\\n",
    "            .sort(F.desc('percentage')).select('rounded_pickup_longitude').collect()\n",
    "\n",
    "valid_pickup_longitude_list = [int(row.rounded_pickup_longitude) for row in valid_pickup_longitude]\n",
    "\n",
    "# df_tripdata.select('*',F.round(col('dropoff_longitude')).alias('rounded_dropoff_longitude'))\\\n",
    "#     .groupBy('rounded_dropoff_longitude').count()\\\n",
    "#         .select(\"*\",(col(\"count\")/total_rows).alias('percentage'))\\\n",
    "#             .filter(\"`percentage` >= 0.01\").sort(F.desc('percentage')).show()\n",
    "\n",
    "# dropoff_longitude - remove 0 latitude as it is invalid\n",
    "# +-------------------------+--------+-------------------+\n",
    "# |rounded_dropoff_longitude|   count|         percentage|\n",
    "# +-------------------------+--------+-------------------+\n",
    "# |                    -74.0|14836719| 0.9825337201469517|\n",
    "# |                      0.0|  261508|0.01731787385662484|\n",
    "# +-------------------------+--------+-------------------+\n",
    "\n",
    "valid_dropoff_longitude = df_tripdata.select('*',F.round(col('dropoff_longitude')).alias('rounded_dropoff_longitude'))\\\n",
    "    .groupBy('rounded_dropoff_longitude').count()\\\n",
    "        .select(\"*\",(col(\"count\")/total_rows).alias('percentage'))\\\n",
    "            .filter(\"`percentage` >= 0.01 and rounded_dropoff_longitude <> 0\")\\\n",
    "            .sort(F.desc('percentage')).select('rounded_dropoff_longitude').collect()\n",
    "\n",
    "valid_dropoff_longitude_list = [int(row.rounded_dropoff_longitude) for row in valid_dropoff_longitude]\n",
    "print('finished 6')\n",
    "#---------------------------------------------------------------------------------------------------------\n",
    "#1. Keep only rounded pickup_latitude in valid_pickup_latitude\n",
    "#2. Keep only rounded pickup_latitude in valid_pickup_latitude\n",
    "#3. Keep only rounded pickup_latitude in valid_dropoff_longitude\n",
    "#4. Keep only rounded pickup_latitude in valid_dropoff_longitude\n",
    "#---------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "##### 7) pickup / dropoff latitude/longitude is identical\n",
    "\n",
    "## Some pickup_lat/long and exactly the same as dropoff_lat/long resulting in 0 geo_distance and null fare_per_mile\n",
    "## remove such records - 116577 rows\n",
    "\n",
    "df_tripdata.filter((col('pickup_latitude')==col('dropoff_latitude'))&(col('pickup_longitude')==col('dropoff_longitude'))),count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows before clesing: 15100468\n",
      "rows after removing missing dropoff coordinates: 15100322\n",
      "rows after removing 0 passenger trips: 15100239\n",
      "rows after removing 0 time trips: 15062346\n",
      "rows after removing 0 distance trips: 14976785\n",
      "rows after removing suspicious pickup/dropoff latitude/longitude: 14734920\n",
      "rows after removing identical pickup/dropoff: 14617675\n"
     ]
    }
   ],
   "source": [
    "#---------------------------------------------------------------------------------------------------------\n",
    "# Data Cleansing - df_tripdata\n",
    "#1. missing dropoff_longiture/ latitude - 146. To be removed\n",
    "#2. Remove passenger count == 0\n",
    "#3. Remove trip_time_in_secs == 0\n",
    "#4. Remove trip_distance == 0\n",
    "#5. Keep only rounded pickup_latitude in valid pickup/dropoff latitude/longitude\n",
    "#6. Remove identical pickup and dropoff\n",
    "#---------------------------------------------------------------------------------------------------------\n",
    "\n",
    "print(f\"rows before clesing: {df_tripdata.count()}\")\n",
    "df_tripdata = df_tripdata.filter(col('dropoff_latitude').isNotNull())\\\n",
    "    .filter(col('dropoff_latitude').isNotNull())\n",
    "print(f\"rows after removing missing dropoff coordinates: {df_tripdata.count()}\")\n",
    "df_tripdata = df_tripdata.filter(col('passenger_count')>0)\n",
    "print(f\"rows after removing 0 passenger trips: {df_tripdata.count()}\")\n",
    "df_tripdata = df_tripdata.filter(col('trip_time_in_secs')>0)\n",
    "print(f\"rows after removing 0 time trips: {df_tripdata.count()}\")\n",
    "df_tripdata = df_tripdata.filter(col('trip_distance')>0)\n",
    "print(f\"rows after removing 0 distance trips: {df_tripdata.count()}\")\n",
    "df_tripdata = df_tripdata.select('*',\n",
    "F.round(col('pickup_latitude')).alias('rounded_pickup_latitude'),\n",
    "F.round(col('pickup_longitude')).alias('rounded_pickup_longitude'),\n",
    "F.round(col('dropoff_latitude')).alias('rounded_dropoff_latitude'),\n",
    "F.round(col('dropoff_longitude')).alias('rounded_dropoff_longitude'))\\\n",
    "    .filter(col('rounded_pickup_latitude').isin(valid_pickup_latitude_list))\\\n",
    "        .filter(col('rounded_pickup_longitude').isin(valid_pickup_longitude_list))\\\n",
    "            .filter(col('rounded_dropoff_latitude').isin(valid_dropoff_latitude_list))\\\n",
    "                .filter(col('rounded_dropoff_longitude').isin(valid_dropoff_longitude_list))\\\n",
    "                    .drop(*['rounded_pickup_latitude','rounded_pickup_longitude',\n",
    "                            'rounded_dropoff_latitude','rounded_dropoff_longitude'])\n",
    "print(f\"rows after removing suspicious pickup/dropoff latitude/longitude: {df_tripdata.count()}\")\n",
    "df_tripdata = df_tripdata.filter((col('pickup_latitude')!=col('dropoff_latitude'))|(col('pickup_longitude')!=col('dropoff_longitude')))\n",
    "print(f\"rows after removing identical pickup/dropoff: {df_tripdata.count()}\")\n",
    "\n",
    "# rows before clesing: 15100468\n",
    "# rows after removing missing dropoff coordinates: 15100322\n",
    "# rows after removing 0 passenger trips: 15100239\n",
    "# rows after removing 0 time trips: 15062346\n",
    "# rows after removing 0 distance trips: 14976785\n",
    "# rows after removing suspicious pickup/dropoff latitude/longitue: 14734920"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### 1) null values\n",
    "##### 2) fare amount\n",
    "##### 3) toll amount\n",
    "##### 4) surcharge\n",
    "##### 5) tip amount\n",
    "##### 6) mta_tax\n",
    "##### 7) total amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------+---------+---------------+------------+-----------+---------+-------+----------+------------+------------+\n",
      "|medallion|hack_license|vendor_id|pickup_datetime|payment_type|fare_amount|surcharge|mta_tax|tip_amount|tolls_amount|total_amount|\n",
      "+---------+------------+---------+---------------+------------+-----------+---------+-------+----------+------------+------------+\n",
      "|        0|           0|        0|              0|           0|          0|        0|      0|         0|           0|           0|\n",
      "+---------+------------+---------+---------------+------------+-----------+---------+-------+----------+------------+------------+\n",
      "\n",
      "cutoff_fare_amount:52.0\n",
      "cutoff_tolls_amount:5.33\n",
      "cutoff_surcharge:1.0\n",
      "cutoff_tip_amount:11.56\n",
      "cutoff_total_amount:69.39\n"
     ]
    }
   ],
   "source": [
    "### Tripfare\n",
    "\n",
    "## 1) null values\n",
    "df_tripfare.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df_tripfare.columns]).show()\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------------\n",
    "#1. No missing values at all\n",
    "#---------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# 2) trip fare, tolls amount, surcharge, tip amount, mta_tax, total amount\n",
    "\n",
    "quantiles_fare_amount = df_tripfare\\\n",
    "    .select(F.percentile_approx(\"fare_amount\", [0.0,0.01,0.25, 0.5, 0.75,0.99,0.995,1.0], 1000000).alias(\"quantiles\")).collect()\n",
    "\n",
    "quantiles_tolls_amount = df_tripfare\\\n",
    "    .select(F.percentile_approx(\"tolls_amount\", [0.0,0.01,0.25, 0.5, 0.75,0.99,0.995,1.0], 1000000).alias(\"quantiles\")).collect()\n",
    "\n",
    "quantiles_surcharge = df_tripfare\\\n",
    "    .select(F.percentile_approx(\"surcharge\", [0.0,0.01,0.25, 0.5, 0.75,0.99,0.995,1.0], 1000000).alias(\"quantiles\")).collect()\n",
    "\n",
    "quantiles_tip_amount = df_tripfare\\\n",
    "    .select(F.percentile_approx(\"tip_amount\", [0.0,0.01,0.25, 0.5, 0.75,0.99,0.995,1.0], 1000000).alias(\"quantiles\")).collect()\n",
    "\n",
    "quantiles_mta_tx = df_tripfare\\\n",
    "    .select(F.percentile_approx(\"mta_tax\", [0.0,0.01,0.25, 0.5, 0.75,0.99,0.995,1.0], 1000000).alias(\"quantiles\")).collect()\n",
    "\n",
    "quantiles_total_amount = df_tripfare\\\n",
    "    .select(F.percentile_approx(\"total_amount\", [0.0,0.01,0.25, 0.5, 0.75,0.99,0.995,1.0], 1000000).alias(\"quantiles\")).collect()\n",
    "\n",
    "# quantiles_fare_amount:[Row(quantiles=[2.5, 3.5, 6.5, 9.5, 14.0, 52.0, 52.0, 500.0])]\n",
    "### minimum fare from websites confirm $2.5 minimum fare\n",
    "# quantiles_tolls_amount:[Row(quantiles=[0.0, 0.0, 0.0, 0.0, 0.0, 5.33, 5.33, 20.0])]\n",
    "# quantiles_surcharge:[Row(quantiles=[0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 1.0, 15.0])]\n",
    "# quantiles_tip_amount:[Row(quantiles=[0.0, 0.0, 0.0, 1.0, 2.0, 10.4, 11.56, 200.0])]\n",
    "# quantiles_total_amount:[Row(quantiles=[2.5, 4.0, 8.0, 11.0, 16.5, 65.62, 69.39, 628.1])]\n",
    "\n",
    "# cutoff at 99.5 percentile\n",
    "cutoff_fare_amount = quantiles_fare_amount[0].quantiles[-2]\n",
    "cutoff_tolls_amount = quantiles_tolls_amount[0].quantiles[-2]\n",
    "cutoff_surcharge = quantiles_surcharge[0].quantiles[-2]\n",
    "cutoff_tip_amount = quantiles_tip_amount[0].quantiles[-2]\n",
    "cutoff_total_amount = quantiles_total_amount[0].quantiles[-2]\n",
    "\n",
    "print(f\"cutoff_fare_amount:{cutoff_fare_amount}\")\n",
    "print(f\"cutoff_tolls_amount:{cutoff_tolls_amount}\")\n",
    "print(f\"cutoff_surcharge:{cutoff_surcharge}\")\n",
    "print(f\"cutoff_tip_amount:{cutoff_tip_amount}\")\n",
    "print(f\"cutoff_total_amount:{cutoff_total_amount}\")\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------------\n",
    "#1. Cutoff 5 amount at 99.5 percentile\n",
    "#---------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows before clesing: 15100468\n",
      "rows after removing extreme amounts above 99.5 percentile: 14971573\n"
     ]
    }
   ],
   "source": [
    "#---------------------------------------------------------------------------------------------------------\n",
    "# Data Cleansing - df_tripfare\n",
    "#1. mCutoff 5 amount at 99.5 percentile\n",
    "#---------------------------------------------------------------------------------------------------------\n",
    "\n",
    "print(f\"rows before clesing: {df_tripfare.count()}\")\n",
    "df_tripfare = df_tripfare\\\n",
    "    .filter(col('fare_amount')<=cutoff_fare_amount)\\\n",
    "        .filter(col('tolls_amount')<=cutoff_tolls_amount)\\\n",
    "            .filter(col('surcharge')<=cutoff_surcharge)\\\n",
    "                .filter(col('tip_amount')<=cutoff_tip_amount)\\\n",
    "                    .filter(col('total_amount')<=cutoff_total_amount)\n",
    "print(f\"rows after removing extreme amounts above 99.5 percentile: {df_tripfare.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enhance latitude longitude data in tripdata for descriptive analytics\n",
    "### get suburb names of pickup and dropoff\n",
    "### categorize trip from pickup-dropoff locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Collect coorditnate from unique 2 decimal-rounded coordinates (1.1km error) from both pickup and dropoff\n",
    "## Call reverse geocode API to get suburb (or county) and city (or state)\n",
    "## Save unique coordinates - area description dictionary to pickle file\n",
    "\n",
    "geolocator = Nominatim(user_agent=\"bikeshare\")\n",
    "reverse = RateLimiter(geolocator.reverse, min_delay_seconds=1, max_retries=0)\n",
    "\n",
    "pickup_latlong_list = df_tripdata.withColumn(\"rounded_lat\",F.round(\"pickup_latitude\", 2))\\\n",
    "    .withColumn(\"rounded_long\",F.round(\"pickup_longitude\", 2))\\\n",
    "    .groupBy('rounded_lat','rounded_long').count().sort(F.desc(\"count\")).toPandas()\\\n",
    "        .apply(lambda row: ', '.join([str(row['rounded_lat']),str(row['rounded_long'])]),axis=1).tolist()\n",
    "\n",
    "dropoff_latlong_list = df_tripdata.withColumn(\"rounded_lat\",F.round(\"dropoff_latitude\", 2))\\\n",
    "    .withColumn(\"rounded_long\",F.round(\"dropoff_longitude\", 2))\\\n",
    "    .groupBy('rounded_lat','rounded_long').count().sort(F.desc(\"count\")).toPandas()\\\n",
    "        .apply(lambda row: ', '.join([str(row['rounded_lat']),str(row['rounded_long'])]),axis=1).tolist()\n",
    "\n",
    "latlong_list = list(set.union(set(pickup_latlong_list),set(dropoff_latlong_list)))\n",
    "print(len(latlong_list))\n",
    "\n",
    "def find_address(latlong):\n",
    "  try:\n",
    "    return reverse(latlong).raw['address']\n",
    "  except:\n",
    "    return 'unknown'\n",
    "\n",
    "latlong_dict = {}\n",
    "for item in latlong_list:\n",
    "  latlong_dict[item] = find_address(item)\n",
    "\n",
    "file_to_write = open(\"latlong_address.pickle\", \"wb\")\n",
    "pickle.dump(latlong_dict, file_to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create new columns - pickup area and dropoff area\n",
    "\n",
    "file_to_read = open(\"latlong_address.pickle\", \"rb\")\n",
    "latlong_dict = pickle.load(file_to_read)\n",
    "\n",
    "def map_area(latlong_str):\n",
    "    ''' get rounded latitude and longitude and return area name'''\n",
    "    if latlong_str in latlong_dict.keys():\n",
    "        address = latlong_dict[latlong_str]\n",
    "        if address == 'unknown':\n",
    "            return 'unknown'\n",
    "        elif ('suburb' in address.keys()) and ('city' in address.keys()):\n",
    "            return ', '.join([address['suburb'],address['city']])\n",
    "        elif ('suburb' in address.keys()) and ('state' in address.keys()):\n",
    "            return ', '.join([address['suburb'],address['state']])\n",
    "        elif ('city_district' in address.keys()) and ('city' in address.keys()):\n",
    "            return ', '.join([address['city_district'],address['city']])\n",
    "        elif 'county' in address.keys():\n",
    "            return ', '.join([address['county'],address['state']])\n",
    "        else:\n",
    "            return 'unknown'\n",
    "    else:\n",
    "        return 'unknown'\n",
    "\n",
    "udf_map_area = udf(map_area,StringType())\n",
    "\n",
    "df_tripdata = df_tripdata.withColumn('pickup_area',\n",
    "udf_map_area(F.concat(F.round(col('pickup_latitude'),2), lit(', '), F.round(col('pickup_longitude'),2))))\\\n",
    "    .withColumn('dropoff_area',\n",
    "udf_map_area(F.concat(F.round(col('dropoff_latitude'),2), lit(', '), F.round(col('dropoff_longitude'),2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "### create new column - geo_distance\n",
    "\n",
    "def calculate_geo_distance(lat1,long1,lat2,long2):\n",
    "    ''' get geo distance between 2 coordinates'''\n",
    "\n",
    "    coord1 = (lat1,long1)\n",
    "    coord2 = (lat2,long2)\n",
    "\n",
    "    try:\n",
    "        return round(distance.distance(coord1, coord2).miles,4)\n",
    "    except:\n",
    "        return 0.0\n",
    "\n",
    "udf_geo_dist = udf(calculate_geo_distance,DoubleType())\n",
    "\n",
    "df_tripdata = df_tripdata.withColumn('geo_distance',\n",
    "udf_geo_dist(col('pickup_latitude'),col('pickup_longitude'),col('dropoff_latitude'),col('dropoff_longitude')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge tripdata and tripfare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['medallion', 'hack_license', 'vendor_id', 'rate_code', 'store_and_fwd_flag', 'pickup_datetime', 'dropoff_datetime', 'passenger_count', 'trip_time_in_secs', 'trip_distance', 'pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude', 'pickup_area', 'dropoff_area', 'geo_distance']\n",
      "['medallion', 'hack_license', 'vendor_id', 'pickup_datetime', 'payment_type', 'fare_amount', 'surcharge', 'mta_tax', 'tip_amount', 'tolls_amount', 'total_amount']\n"
     ]
    }
   ],
   "source": [
    "# print(df_tripdata.schema.names)\n",
    "# print(df_tripfare.schema.names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14734920, 17)\n",
      "(14971573, 11)\n",
      "(14623320, 25)\n"
     ]
    }
   ],
   "source": [
    "joining_keys = [i for i in df_tripdata.schema.names if i in df_tripfare.schema.names]\n",
    "\n",
    "df_trip = df_tripdata.join(df_tripfare,joining_keys,'inner')\n",
    "\n",
    "### add trip_id\n",
    "w = Window().orderBy(col('pickup_datetime'))\n",
    "df_trip = df_trip.withColumn('trip_id', F.row_number().over(w))\n",
    "\n",
    "print((df_tripdata.count(), len(df_tripdata.columns)))\n",
    "print((df_tripfare.count(), len(df_tripfare.columns)))\n",
    "print((df_trip.count(), len(df_trip.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create taxi_driver_dim table and save as parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### get taxi_id and driver_id\n",
    "df_taxi_id = df_trip.select('medallion').groupBy('medallion').count().toPandas()\\\n",
    "    .reset_index().rename(columns={'index':'taxi_id'}).drop(columns='count',axis=1)\n",
    "\n",
    "df_driver_id = df_trip.select('hack_license').groupBy('hack_license').count().toPandas()\\\n",
    "    .reset_index().rename(columns={'index':'driver_id'}).drop(columns='count',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### check if there's overlap in medallion and day in which multiple hack_license were driving the same car\n",
    "\n",
    "## add pickup_date to df_trip\n",
    "datestrip = udf(lambda x: x[:10],StringType())\n",
    "df_trip = df_trip.withColumn('pickup_date',datestrip(col('pickup_datetime')))\n",
    "\n",
    "df_mult_hack_chk = df_trip.select('medallion','hack_license','pickup_date')\\\n",
    "    .groupBy('medallion','pickup_date','hack_license').count()\\\n",
    "        .groupBy('medallion','pickup_date').count().toPandas()\n",
    "\n",
    "## check multiple hack license\n",
    "\n",
    "# df_mult_hack_chk.groupby(by='count',as_index=False)[['medallion']].agg({'medallion':'count'})\n",
    "\n",
    "# Sharing car between 2 or 3 hack license looks genuine.\n",
    "# no. of hack license in a day\tno. of madallions occupied by those hack license in a day\n",
    "# 1\t                            81207\n",
    "# 2\t                            248817\n",
    "# 3\t                            53821\n",
    "# 4\t                            547\n",
    "# 5\t                            4\n",
    "# 7\t                            1\n",
    "# 14\t                        1\n",
    "# 30\t                        1\n",
    "\n",
    "\n",
    "#### Add taxi_id and driver_id\n",
    "\n",
    "df_taxi_driver_dim = df_trip.select('medallion','hack_license').groupBy('medallion','hack_license').count().toPandas()\\\n",
    "    .reset_index().rename(columns={'index':'taxi_driver_id'}).drop(columns='count',axis=1)\n",
    "print(df_taxi_driver_dim.shape)\n",
    "df_taxi_driver_dim = df_taxi_driver_dim.merge(df_taxi_id,how='left',on='medallion')\n",
    "print(df_taxi_driver_dim.shape)\n",
    "df_taxi_driver_dim = df_taxi_driver_dim.merge(df_driver_id,how='left',on='hack_license')\n",
    "print(df_taxi_driver_dim.shape)\n",
    "\n",
    "### Save taxi_driver_dim as parquet\n",
    "df_taxi_driver_dim.to_parquet('spark-warehouse/taxi_driver_dim.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Taxi Driver ID to df_trip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add Taxi Driver ID, Taxi ID, Driver ID to df_trip\n",
    "\n",
    "taxi_driver_dim_spark_df =spark.createDataFrame(df_taxi_driver_dim) \n",
    "joining_keys = ['medallion','hack_license']\n",
    "df_trip = df_trip.join(taxi_driver_dim_spark_df,joining_keys,'inner')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write to Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trip.write.format('parquet').saveAsTable('trip_clean_all')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c818777a6ad54da25b094a50dfb6e8ddd7f4bf040e5d0005aff88d6d371533f0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
